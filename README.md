# TrialsOfAIFootballCommentator
This isn't a fully developed project, and I've just put it here for my reference.

This is an attempt to build a video description system using deep learning that can identify the actions and significant events occurring in a video and generate natural language responses that are appropriate to the given video. These responses should be intelligent observations and correctly acknowledge the attribute of each specific frame of the video. It will act as an ‘AI commentator’ for the given domain. The working of the model is as follows. Download a video from YouTube( one that covers all the attributes expected for the functioning of the model and also has audio commentary & subtitles that the model will be trained on ). First import and read the video, extracts frames from it and saves them as images. Label few of the images of the dataset to train the model and store them in a csv file. Then, build the model on our training data. Use this model to make predictions for the remaining images of the given video. Next, pick another video of the same format, domain and context. Extract frames from this video and use the previously built prediction model to classify the images of this video. The end results of this process is the entire video being described and assigned attributes to each frame of it. The other module of this project is to generate responses for the events. Do two simultaneous actions for this purpose. First, use the assigned attributes to identify the sentiment and the entities involved to generate responses. Second, use the subtitles and audio to assign a second set of attributes to the frames. Use this set of attributes and the transcript of the video to train a model for natural language generation.

Automatic video description involves understanding of many entities and the detection of their occurrences in a video employing computer vision techniques. These entities include background scene, humans, objects, human actions, human-object interactions, human-human interactions, other events, and the order in which events occur. All this information must then be articulated using a comprehensible and grammatically correct text employing Natural Language Processing (NLP) techniques. Over the past few years, these two traditionally independent fields, Computer Vision (CV) and Natural Language Processing (NLP) have joined forces to address the upsurge of research interests in understanding and describing images and videos.

However, where AI’s limitations are clearly visible is when it comes to AI gameplay commentary. The work in this field looks nowhere close to passing the Turing test. When watching sport on TV, the footage is often only half the experience. A good commentator can make all the difference, peppering a play-by-play account of the action with expert knowledge and anecdotes. But even the best commentator’s repertoire is limited. 
 
The commentary has to be both engaging and instructive at different situations in a video game. An AI system can step up to solve this problem. This work draws on convolutional neural networks (CNNs) to predict commentary for a particular frame of a gameplay video. CNNs have been employed to take an input snapshot of a game and predict player experience and offer comments accordingly

The system should be able to learn from the videos of matches provided as training data from YouTube and tabular datasets that provide statistics of players to make perceptive comments, which are actuated via a text-to-speech package. 

This project contains an aggregate of :
A basic MLP regression model to generate insights about players from a Fifa 18 dataset from kaggle.
An open domain context answering system using a pre-trained DeepPavlov engine.
A sample of using the text-to-speech module to actuate speech.
A script that generates sports highlights automatically using audio processing to determine key events.
A script to detect sound events(doesn't work yet).
An event/object detection script that currently calculates screentime of 'actors'. (To be modified for our purpose of event detection like goals, fouls etc.)

I tried this project early this year and wasn't able to complete this project. From reading a few deep learning papers ( particularly regarding attention models ) I've planned to work on a seq2seq deep learning model that can include multiple functionalities, rather than modularise this task way too much. I will attempt this task again when I've obtained a deeper understanding of the necessary concepts and task at hand.
