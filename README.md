# TrialsOfAIFootballCommentator

This is an attempt to build a video description system using deep learning that can identify the actions and significant events occurring in a video and generate natural language responses that are appropriate to the given video. These responses should be intelligent observations and correctly acknowledge the attribute of each specific frame of the video. It will act as an ‘AI commentator’ for the given domain. The working of the model is as follows. We download a video from YouTube( one that covers all the attributes expected for the functioning of the model and also has audio commentary & subtitles that the model will be trained on ). We first import and read the video, extracts frames from it and saves them as images. We label few of the images of the dataset to train the model and store them in a csv file. Then, we build the model on our training data. We use this model to make predictions for the remaining images of the given video. Next, we pick another video of the same format, domain and context. We extract frames from this video and use the previously built prediction model to classify the images of this video. The end results of this process is the entire video being described and assigned attributes to each frame of it. The other module of this project is to generate responses for the events. We do two simultaneous actions for this purpose. First, we use the assigned attributes to identify the sentiment and the entities involved to generate responses. Second, we use the subtitles and audio to assign a second set of attributes to the frames. We shall use this set of attributes and the transcript of the video to train a model for natural language generation.
